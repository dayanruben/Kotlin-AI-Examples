{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T14:37:18.824144Z",
     "start_time": "2025-11-30T14:37:18.257594Z"
    }
   },
   "source": [
    "%useLatestDescriptors\n",
    "%use langchain4j"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:37:19.114022Z",
     "start_time": "2025-11-30T14:37:18.828333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val openAiApiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR-OPENAI-API-KEY\"\n",
    "\n",
    "/**\n",
    " * A function to split text into chunks.\n",
    " * For simplicity, this example splits the text by sentences ('.')\n",
    " * and then re-joins them into chunks if the chunk size is under a limit.\n",
    " */\n",
    "fun splitIntoChunks(text: String, maxTokensPerChunk: Int = 300): List<String> {\n",
    "    // Very simplified approach:\n",
    "    val sentences = text.split(\".\")\n",
    "    val chunks = mutableListOf<String>()\n",
    "    val currentChunk = StringBuilder()\n",
    "\n",
    "    for (sentence in sentences) {\n",
    "        val potentialChunk = if (currentChunk.isEmpty()) sentence else \"${currentChunk.trim()}. $sentence\"\n",
    "        // Here you would estimate token count; for simplicity, we use character length.\n",
    "        // For robust token-based splits, you could integrate a tokenizer class from the library.\n",
    "        if (potentialChunk.length < maxTokensPerChunk) {\n",
    "            if (currentChunk.isNotEmpty()) {\n",
    "                currentChunk.append(\". \")\n",
    "            }\n",
    "            currentChunk.append(sentence)\n",
    "        } else {\n",
    "            // Add the current chunk and start a new one\n",
    "            chunks.add(currentChunk.toString())\n",
    "            currentChunk.clear()\n",
    "            currentChunk.append(sentence)\n",
    "        }\n",
    "    }\n",
    "    // Add the last chunk if it’s not empty\n",
    "    if (currentChunk.isNotEmpty()) {\n",
    "        chunks.add(currentChunk.toString())\n",
    "    }\n",
    "    return chunks\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:37:19.211014Z",
     "start_time": "2025-11-30T14:37:19.114665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.langchain4j.data.message.UserMessage.userMessage\n",
    "import dev.langchain4j.model.chat.request.ChatRequest\n",
    "import dev.langchain4j.model.openai.OpenAiChatModel\n",
    "\n",
    "/**\n",
    " * A pseudo function that sends the prompt to an OpenAI LLM and returns the completion.\n",
    " * In a real scenario, you’d use something like:\n",
    " * OpenAiService.builder()\n",
    " *   .openAiApiKey(openAiApiKey)\n",
    " *   .build()\n",
    " * and then create an LLM chain. This is just a placeholder for demonstration.\n",
    " */\n",
    "fun summarizeChunkWithOpenAI(chunk: String, openAiApiKey: String): String {\n",
    "    val openAi = OpenAiChatModel.builder()\n",
    "        .apiKey(openAiApiKey)\n",
    "        .modelName(\"gpt-4\")\n",
    "        .temperature(0.7)\n",
    "        .build()\n",
    "\n",
    "    val prompt = \"Please summarize the following text:\\n\\n$chunk\"\n",
    "\n",
    "    // Send the request to get the actual summary\n",
    "    val response = openAi.chat(userMessage(prompt))\n",
    "\n",
    "    // Extract the content from the response\n",
    "    return response.aiMessage().text()\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:37:19.397754Z",
     "start_time": "2025-11-30T14:37:19.221998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "/**\n",
    " * Summarizes a large document by splitting it into chunks, summarizing each chunk,\n",
    " * and combining the results.\n",
    " */\n",
    "fun summarizeDocument(\n",
    "    text: String,\n",
    "    detail: Double = 0.0,\n",
    "    maxTokensPerChunk: Int = 500\n",
    "): String {\n",
    "    require(detail in 0.0..1.0) { \"Detail must be between 0.0 and 1.0\" }\n",
    "\n",
    "    // Split the text into an initial set of chunks\n",
    "    val initialChunks = splitIntoChunks(text, maxTokensPerChunk)\n",
    "    // Interpolate number of chunks based on the detail desired\n",
    "    val maxChunks = initialChunks.size\n",
    "    val minChunks = 1\n",
    "    val targetChunksCount = (minChunks + detail * (maxChunks - minChunks)).toInt().coerceAtLeast(1)\n",
    "\n",
    "    // Recalculate chunk size to approximate the target number of chunks\n",
    "    // (For a real application, you might do more advanced splitting)\n",
    "    val totalLength = text.length\n",
    "    val adjustedChunkSize = (totalLength / targetChunksCount).coerceAtLeast(200)\n",
    "    val finalChunks = splitIntoChunks(text, adjustedChunkSize)\n",
    "\n",
    "    // Summarize each chunk individually\n",
    "    val chunkSummaries = finalChunks.map { chunk ->\n",
    "        summarizeChunkWithOpenAI(chunk, openAiApiKey)\n",
    "    }\n",
    "\n",
    "    // Combine all chunk summaries into a final summary\n",
    "    return chunkSummaries.joinToString(separator = \"\\n\\n\")\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:37:19.439788Z",
     "start_time": "2025-11-30T14:37:19.398451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val artificialIntelligenceWikipediaText = File(\"data/artificial_intelligence_wikipedia.txt\").readText(Charsets.UTF_8)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:45:55.271830Z",
     "start_time": "2025-11-30T14:37:19.440632Z"
    }
   },
   "cell_type": "code",
   "source": "val summaryDetail = summarizeDocument(artificialIntelligenceWikipediaText, detail = 1.0)",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:45:58.400158Z",
     "start_time": "2025-11-30T14:45:55.272847Z"
    }
   },
   "cell_type": "code",
   "source": "println(\"Summary with detail=1.0:\\n$summaryDetail\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary with detail=1.0:\n",
      "Artificial intelligence (AI) is the display of intelligence by machines, especially computer systems. It is a research field within computer science that focuses on creating and studying methods and software that allow machines to understand their environment and use learning and intelligence to perform actions that increase their likelihood of achieving set goals.\n",
      "\n",
      ". , self-driving cars); and applications in healthcare, defense, and financial services. These applications are often referred to as AI technology.\n",
      "\n",
      "The text discusses the use of artificial intelligence (AI) in different fields such as autonomous vehicles, creative tools, and strategy games. However, it also points out that many AI applications are not recognized as such. This is because once AI becomes extremely useful and common in a particular application, it is no longer labeled as AI.\n",
      "\n",
      "Alan Turing was the pioneer of substantial research in what he labeled as machine intelligence. The academic discipline of artificial intelligence (AI) was established in 1956. The field experienced numerous cycles of optimism and periods of disappointment, leading to funding loss, a phase termed as AI winter.\n",
      "\n",
      "Funding and interest in artificial intelligence (AI) significantly increased after 2012 when deep learning techniques surpassed previous AI methods, and again after 2017 with the development of the transformer architecture. This resulted in the AI boom in the early 2020s, where companies, universities, and labs, mostly based in the United States, made substantial advancements in AI.\n",
      "\n",
      "The increasing use of artificial intelligence in the 21st century is causing societal and economic changes, with greater automation and reliance on data for decision-making. AI is being integrated into numerous sectors including job markets, healthcare, government, industry, and education, influencing all aspects of life.\n",
      "\n",
      "The text discusses the long-term effects, ethical implications, and risks of artificial intelligence (AI), suggesting the need for regulatory policies to guarantee its safety and benefits. It also mentions that AI research is divided into various sub-fields, each focused on specific goals and tools.\n",
      "\n",
      "The main objectives of AI research encompass reasoning, knowledge representation, planning, learning, natural language processing, perception, and robotics support. A paramount long-term goal in the field is to achieve general intelligence, which is the ability to perform any task that a human can do, but at least at an equal level.\n",
      "\n",
      "AI researchers employ a variety of techniques to achieve their goals, such as search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research and economics. AI also utilizes knowledge from psychology, linguistics, philosophy, neuroscience and other fields.\n",
      "\n",
      "The main objective of simulating or creating intelligence has been divided into smaller issues. These sub-problems involve specific characteristics or abilities that researchers anticipate an intelligent system would exhibit. The traits that have been most researched and encompass the range of AI studies are discussed below.\n",
      "\n",
      "The text discusses the evolution of algorithms in problem-solving. Early researchers created algorithms that mimic the sequential reasoning humans use in solving puzzles or making logical deductions. By the late 1980s and 1990s, methods were developed to handle uncertain or incomplete information, incorporating concepts from fields such as probability and economics.\n",
      "\n",
      "Many algorithms struggle to solve large reasoning problems as they become exponentially slower with the increase in problem size, a phenomenon known as \"combinatorial explosion\". Humans, in contrast, often don't use step-by-step deduction, as early AI research could replicate, but rather solve problems using quick, intuitive judgments.\n",
      "\n",
      "The text discusses the unresolved issue of accurate and efficient reasoning. It introduces the concept of ontology in knowledge representation, which depicts knowledge as a set of concepts within a domain and their relationships. This, combined with knowledge engineering, enables AI programs to intelligently answer questions and make deductions about real-world facts.\n",
      "\n",
      "Formal knowledge representations are used in various fields such as content-based indexing and retrieval, scene interpretation, clinical decision support, and knowledge discovery from large databases. A knowledge base refers to a body of knowledge that is represented in a format that can be utilized by a program.\n",
      "\n",
      "An ontology is the collection of elements such as objects, relations, concepts, and properties utilized in a specific knowledge domain.\n",
      "\n",
      "Knowledge bases are required to represent various aspects and domains of knowledge, including objects, properties, categories, relations between objects, situations, events, states, time, causes and effects, and knowledge about knowledge. They also need to cater to default reasoning, which refers to assumptions that are considered true until proven otherwise, and remain constant despite changes in other facts.\n",
      "\n",
      "The text highlights two major challenges in knowledge representation: the vast amount of commonsense knowledge that an average person possesses, and the fact that most of this knowledge is not in a form that can be verbally expressed as facts or statements.\n",
      "\n",
      "The text discusses challenges in artificial intelligence (AI), including the difficulty of knowledge acquisition - obtaining necessary knowledge for AI applications. It also introduces the concept of an \"agent\" in AI, which is something that perceives and acts in the world. A rational agent has goals or preferences and takes actions to achieve them, particularly in automated planning where the agent has a specific goal.\n",
      "\n",
      "In automated decision making, the agent assigns a numerical value, known as \"utility\", to each situation based on its preferences. This number indicates how much the agent prefers or wants to avoid a certain situation.\n",
      "\n",
      "The text describes a process where for every possible action, its \"expected utility\" can be calculated. This is done by considering the utility of all possible outcomes of the action, and factoring in the likelihood of each outcome. The action with the highest expected utility is then chosen. In classical planning, the agent is aware of the exact impact of any action.\n",
      "\n",
      "The text discusses the challenges typically faced in real-world situations, where the agent, or decision-maker, is often uncertain about their exact circumstances or the outcomes of their potential actions. Therefore, the agent must make decisions based on probabilistic predictions and then re-evaluate the situation based on the results of those actions.\n",
      "\n",
      "The text discusses how an agent's preferences can sometimes be uncertain, particularly when other agents or humans are involved. This uncertainty can be addressed through learning techniques like inverse reinforcement learning or by the agent seeking additional information to refine its preferences. The text also mentions the application of information value theory to assess the worth of exploratory or experimental actions.\n",
      "\n",
      "Agents must make decisions and evaluate situations in the vast space of potential future actions and situations. However, due to the complexity and size of this space, they must do so while uncertain of the results.\n",
      "\n",
      "A Markov decision process includes a transition model and a reward function. The former predicts the probability of an action changing the state in a certain way, while the latter provides the utility of each state and the cost of every action. A policy, which can be calculated, heuristic, or learned, pairs a decision with each possible state.\n",
      "\n",
      "Game theory is a method used in AI programs to outline rational behavior of multiple interacting agents, especially in decision-making processes. Machine learning, which is a fundamental part of AI, refers to the study of programs that can automatically enhance their performance on a specific task. There are various types of machine learning.\n",
      "\n",
      "Unsupervised learning uses data to find patterns and make predictions without guidance, while supervised learning needs a human to label the input data. The two main types of supervised learning are classification, where the program predicts the category of the input, and regression, where the program deduces a numeric function based on numeric input.\n",
      "\n",
      "Reinforcement learning is a process where an agent learns to make good choices by receiving rewards for good responses and punishments for bad ones. Transfer learning, on the other hand, involves applying knowledge acquired from one problem to a new problem.\n",
      "\n",
      "Deep learning is a form of machine learning that uses artificial neural networks inspired by biology for various types of learning. Computational learning theory evaluates learners based on computational complexity, sample complexity (the amount of data needed), or other optimization concepts.\n",
      "\n",
      "Natural language processing (NLP) is a technology that enables software to interact in human languages like English. It deals with specific issues such as speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\n",
      "\n",
      "Early studies, influenced by Noam Chomsky's generative grammar and semantic networks, struggled with distinguishing between different meanings of a word unless they were limited to small specific areas, referred to as \"micro-worlds\". This was due to the problem of common sense knowledge.\n",
      "\n",
      "Margaret Masterman argued that understanding languages relies more on meaning than grammar. She suggested that computational language structure should be based on thesauri, not dictionaries.\n",
      "\n",
      "The modern deep learning techniques for Natural Language Processing (NLP) include word embedding, which represents words as vectors encoding their meaning, and transformers, a deep learning architecture that uses an attention mechanism, among others.\n",
      "\n",
      "In 2019, generative pre-trained transformer (GPT) language models started to produce coherent text. By 2023, these models achieved human-level scores on various tests including the bar exam, SAT, GRE, and were applied in many other real-world situations.\n",
      "\n",
      "\n",
      "Machine perception refers to the capacity to interpret sensor inputs (like cameras, microphones, wireless signals, etc.) to understand aspects of the world. This encompasses computer vision, which is the analysis of visual input. Areas within this field include speech and facial recognition, image and object classification, and robotic perception.\n",
      "\n",
      "Social intelligence refers to systems like Kismet, a robot head developed in the 1990s, which can recognize and simulate emotions. This falls under the interdisciplinary field of affective computing, which includes systems that can recognize, interpret, process, or simulate human feelings, emotions, and moods.\n",
      "\n",
      "The text explains that some virtual assistants are designed to speak conversationally or humorously to mimic human interaction and seem more emotionally aware. However, this can lead to a misleading perception of these computer agents' actual intelligence level, especially among inexperienced users.\n",
      "\n",
      "The text discusses some moderate successes in affective computing, which include textual sentiment analysis and multimodal sentiment analysis. This involves AI classifying the emotional responses displayed by a subject in a video. It also mentions artificial general intelligence, suggesting that a machine with this type of intelligence should be capable of solving a wide range of problems with similar breadth and versatility to human intelligence.\n",
      "\n",
      "AI research employs numerous methods to achieve its aims, including search and optimization techniques. AI can resolve various issues by smartly searching through numerous potential solutions. Two types of search used in AI are state space search and local search.\n",
      "\n",
      "State space search is a process that explores a tree of potential states to locate a goal state. This method is frequently used in planning algorithms, which sift through trees of goals and subgoals to find a route to a desired goal, a process known as means-ends analysis.\n",
      "\n",
      "Exhaustive searches are often insufficient for real-world problems as the number of potential areas to search can become too large, resulting in an extremely slow or never-ending search. To solve this, heuristics or rules of thumb can be used to prioritize choices that are more likely to achieve the intended goal.\n",
      "\n",
      "The text describes two types of search methods used in AI and programming. Adversarial search is utilized in game-playing programs like chess or Go, where it explores a tree of potential moves and counter-moves to find a winning position. Local search, exemplified by gradient descent, adjusts two parameters to minimize the loss function. Different starting points can influence the outcome.\n",
      "\n",
      "Local search is a method that uses mathematical optimization to solve problems by refining an initial guess. Gradient descent, a form of local search, optimizes numerical parameters by incrementally adjusting them to reduce a loss function. This method is often used to train neural networks.\n",
      "\n",
      "Evolutionary computation is a type of local search that aims to progressively enhance a set of potential solutions by mutating and recombining them, with only the fittest surviving each generation. Distributed search processes can be coordinated through swarm intelligence algorithms.\n",
      "\n",
      "The text mentions two popular swarm algorithms used in search, namely particle swarm optimization, which is inspired by bird flocking, and ant colony optimization, inspired by ant trails. It also mentions that formal logic is used for reasoning and knowledge representation.\n",
      "\n",
      "Formal logic is divided into two main types: propositional logic and predicate logic. Propositional logic deals with true or false statements and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\". On the other hand, predicate logic operates on objects, predicates, and relations and employs quantifiers like \"Every X is a Y\" and \"There are some Xs that are Ys\".\n",
      "\n",
      "Deductive reasoning in logic involves validating a new statement based on other given statements assumed to be true. The structure of proofs can be visualized as proof trees, where nodes represent sentences and the connections between parent and children nodes are determined by inference rules.\n",
      "\n",
      "Problem-solving involves searching for a proof tree where the root node is marked by the problem's solution and the leaf nodes by premises or axioms. In the context of Horn clauses, this search can be carried out by reasoning either forwards from the premises or backwards from the problem.\n",
      "\n",
      "The text explains that in first-order logic, resolution is an inference rule that solves a problem by proving a contradiction from premises, including the negation of the problem. It also states that inference in both Horn clause logic and first-order logic is undecidable and intractable.\n",
      "\n",
      "Backward reasoning with Horn clauses, a method used in Prolog, a logic programming language, is Turing complete, meaning it can simulate a Turing machine. It is also as efficient as other symbolic programming languages. Fuzzy logic, on the other hand, assigns a value between 0 and 1 to represent the \"degree of truth,\" allowing it to manage propositions that are partially true or vague.\n",
      "\n",
      "Non-monotonic logics and logic programming with negation as failure are created to deal with default reasoning. Specialized versions of logic have also been created to explain various complex domains.\n",
      "\n",
      "The text discusses the use of probabilistic methods in artificial intelligence (AI) to handle uncertain or incomplete information. These methods, derived from probability theory and economics, are employed in various AI domains such as reasoning, planning, learning, perception, and robotics. The text also mentions the use of a Bayesian network, which comes with associated conditional probability tables.\n",
      "\n",
      "The text discusses the development of precise mathematical tools to examine how an agent can make choices and plan. These tools, which are based on decision theory, decision analysis, and information value theory, include models like Markov decision processes, dynamic decision networks, game theory, and mechanism design.\n",
      "\n",
      "Bayesian networks are a tool used for various tasks such as reasoning via the Bayesian inference algorithm, learning through the expectation-maximization algorithm, planning with decision networks, and perception using dynamic Bayesian networks.\n",
      "\n",
      "Probabilistic algorithms can be utilized for various tasks such as filtering, predicting, smoothing, and interpreting streams of data. They assist perception systems in analyzing processes that unfold over time, such as hidden Markov models or Kalman filters.\n",
      "\n",
      ", \"if hot then cool\"), on the other. Expectation-maximization clustering is an effective method for accurately categorizing data, such as the eruption patterns of Old Faithful geyser.\n",
      "\n",
      "The text discusses classifiers, which are functions that use pattern matching to identify the closest match. These classifiers can be adjusted or fine-tuned through supervised learning using selected examples. Each pattern or observation is associated with a predefined class. The combination of all observations and their respective class labels constitute a data set.\n",
      "\n",
      "The text explains that when a new observation is received, it is classified based on past experience. Among the many types of classifiers used, the decision tree is the simplest and most commonly used symbolic machine learning algorithm.\n",
      "\n",
      "The K-nearest neighbor algorithm was the most commonly used analogical AI until the mid-1990s, when Kernel methods like the support vector machine took over. The naive Bayes classifier is said to be the \"most widely used learner\" at Google, largely because of its scalability. Neural networks are also utilized as classifiers.\n",
      "\n",
      "An artificial neural network is a system of interconnected nodes, or artificial neurons, designed to mimic the neurons in a human brain. This network is trained to recognize certain patterns and, once trained, it can identify these patterns in new data.\n",
      "\n",
      "A deep neural network consists of an input, at least two hidden layers of nodes, and an output. Each node applies a function and when the weight surpasses a specified threshold, the data is sent to the next layer.\n",
      "\n",
      "Learning algorithms for neural networks use local search to select the appropriate weights during training, with the backpropagation algorithm being the most common technique. Neural networks are capable of modeling complex relationships between inputs and outputs and identifying patterns in data. Theoretically, they can learn any function.\n",
      "\n",
      "Feedforward neural networks pass signals in one direction, while recurrent neural networks feed output signals back into the input, facilitating short-term memory of past inputs. Among recurrent networks, long short-term memory is the most effective architecture. Perceptrons use only a single layer of neurons, while deep learning utilizes multiple layers.\n",
      "\n",
      "Convolutional neural networks enhance the relationship between neurons that are near each other, which is crucial in image processing. Here, a specific group of neurons must identify an 'edge' before the network can recognize an object. Deep learning uses multiple layers of neurons between the network's inputs and outputs.\n",
      "\n",
      "The text describes how multiple layers in image processing can gradually extract more complex features from raw input. Lower layers identify simpler aspects like edges, while higher layers recognize more advanced concepts like digits, letters, or faces.\n",
      "\n",
      "Deep learning has significantly enhanced the performance of programs in various subfields of artificial intelligence, such as computer vision, speech recognition, natural language processing, and image classification. However, as of 2023, the reason for deep learning's success in these applications is not understood.\n",
      "\n",
      "The rapid success of deep learning from 2012-2015 was not due to any new discovery or theoretical breakthrough, as deep neural networks and backpropagation had been described as far back as the 1950s. Rather, it was due to two main factors: a significant increase in computer power, including a hundred-fold increase in speed due to the use of GPUs, and the availability of large amounts of training data, particularly the large curated datasets used for benchmark testing, such as ImageNet.\n",
      "\n",
      "Generative pre-trained transformers (GPT) are language models that focus on semantic relationships between words in sentences. These text-based models are pre-trained on a large amount of text data, often sourced from the internet. The pre-training process involves predicting the next token, which could be a word, subword, or punctuation mark.\n",
      "\n",
      "This text discusses the pre-training of GPT models, during which they gather knowledge about the world. These models can then generate human-like text by predicting the next token repeatedly. Usually, a subsequent training phase enhances the model's accuracy, usefulness, and safety, often utilizing a technique known as reinforcement learning from human feedback (RLHF).\n",
      "\n",
      "Current Generative Pre-training Transformer (GPT) models are used in chatbots, allowing users to ask questions or request tasks in simple text. However, these models can generate false information, known as \"hallucinations\", though this can be minimized with RLHF and quality data. Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA.\n",
      "\n",
      "Multimodal GPT models have the ability to process various types of data, including images, videos, sound, and text.\n",
      "\n",
      "In the late 2010s, graphics processing units (GPUs) with AI-specific enhancements replaced central processing units (CPUs) as the primary tool for training large-scale machine learning models in both commercial and academic settings. This shift was facilitated by the use of specialized TensorFlow software.\n",
      "\n",
      "The text mentions that historically, specialized languages like Lisp, Prolog, Python and others have been used.\n",
      "\n",
      "Artificial Intelligence (AI) and machine learning technologies are extensively used in various applications in the 2020s. These include Google Search, online advertisement targeting, recommendation systems offered by platforms like Netflix, YouTube, or Amazon, driving internet traffic, targeted advertising like AdSense and Facebook, virtual assistants such as Siri or Alexa, autonomous vehicles including drones, ADAS, and self-driving cars. Other applications include automatic language translation by software like Microsoft Translator and Google Translate, facial recognition as seen in Apple's Face ID, Microsoft's DeepFace, and Google's FaceNet, and image labeling used by Facebook, Apple's iPhoto, and TikTok.\n",
      "\n",
      "The application of artificial intelligence (AI) in healthcare could potentially enhance patient care and improve quality of life. From an ethical perspective, medical professionals are obliged to use AI if it can provide more accurate diagnoses and treatment for patients.\n",
      "\n",
      "AI is a critical tool in medical research, especially in processing and integrating large amounts of data. It is especially useful in organoid and tissue engineering development that heavily rely on microscopy imaging. AI also has the potential to address disparities in funding distribution across different research fields.\n",
      "\n",
      "New AI tools have significant potential in the field of biomedicine. For instance, AlphaFold 2, released in 2021, was able to determine the 3D structure of a protein in a matter of hours as opposed to months. Furthermore, by 2023, AI was instrumental in discovering a new class of antibiotics that could eliminate two types of drug-resistant bacteria.\n",
      "\n",
      "The text discusses the use of game playing programs to demonstrate and test advanced artificial intelligence techniques since the 1950s. It highlights the achievement of Deep Blue, the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.\n",
      "\n",
      "In 2011, IBM's question answering system, Watson, won a Jeopardy! exhibition match against top champions Brad Rutter and Ken Jennings. Then, in March 2016, a computer system named AlphaGo defeated Go champion Lee Sedol in 4 out of 5 games, marking the first time a computer system beat a professional Go player without handicaps.\n",
      "\n",
      "In 2017, an AI defeated Ke Jie, the world's best Go player. Other AI programs like Pluribus can handle imperfect-information games like poker. DeepMind has also developed generalistic reinforcement learning models like MuZero, which can be trained to play chess, Go, or Atari games.\n",
      "\n",
      "In 2019, DeepMind's AI, AlphaStar, reached grandmaster level in StarCraft II, a complex real-time strategy game. Then in 2021, an AI agent competed in a PlayStation Gran Turismo competition, defeating four of the world's top players using deep reinforcement learning.\n",
      "\n",
      "Countries worldwide are implementing artificial intelligence (AI) in their military operations. The primary uses of AI are to improve command and control, communications, sensors, integration, and interoperability. Areas of research include intelligence gathering and analysis, logistics, cyber operations, information operations, and semi-autonomous and autonomous vehicles.\n",
      "\n",
      "AI technologies support military operations by coordinating sensors and effectors, detecting and identifying threats, marking enemy positions, acquiring targets, and coordinating Joint Fires between manned and unmanned teams. These technologies were utilized in military operations in Iraq and Syria.\n",
      "\n",
      "In November 2023, US Vice President Kamala Harris announced a pledge signed by 31 countries to regulate the military use of artificial intelligence (AI). The agreement includes conducting legal reviews to ensure military AI complies with international laws and promoting caution and transparency in its development.\n",
      "\n",
      "Generative AI, a type of artificial intelligence, gained significant attention in the early 2020s. By March 2023, 58% of US adults knew about ChatGPT, a generative AI application, and 14% had used it.\n",
      "\n",
      "AI-based text-to-image generators, including Midjourney, DALL-E, and Stable Diffusion, have gained widespread attention due to their increasing realism and ease of use. This has led to a trend of viral AI-generated photos, such as a fake image of Pope Francis in a white puffer coat, a fictional arrest of Donald Trump, and a hoax attack on the Pentagon. These tools are also being used in professional creative arts.\n",
      "\n",
      "The text discusses the prevalence of AI applications in various industries. As per a 2017 survey, 20% of companies stated that they had integrated AI into some of their offerings or processes. This highlights the widespread use of AI to address specific problems unique to certain industries or institutions.\n",
      "\n",
      "The text provides examples of areas where artificial intelligence (AI) is utilized, including energy storage, medical diagnosis, military logistics, predicting judicial decisions, foreign policy, and supply chain management. In agriculture, AI assists farmers in identifying areas requiring irrigation, fertilization, pesticide treatments, and yield increase. AI is also used by agronomists for research and development.\n",
      "\n",
      "Artificial Intelligence (AI) is being utilized in various ways in agriculture. These include predicting crop ripening time, monitoring soil moisture, operating agricultural robots, conducting predictive analytics, classifying livestock emotions, automating greenhouses, detecting diseases and pests, and conserving water.\n",
      "\n",
      "Artificial intelligence (AI) is being utilized in the field of astronomy to manage and analyze the growing volumes of data. The applications of AI include classification, regression, clustering, forecasting, generation, discovery, and the development of scientific insights. These applications are helpful in tasks like discovering exoplanets, predicting solar activity, and differentiating between signals and instrumental effects in gravitational wave astronomy.\n",
      "\n",
      "The text discusses the potential use of artificial intelligence (AI) in space activities like exploration, data analysis from missions, real-time decisions of spacecraft, and space debris avoidance. It also highlights that AI has both potential benefits and risks, and the ethical considerations of AI are also important.\n",
      "\n",
      "AI has the potential to advance science and solve significant problems, according to Demis Hassabis of Deep Mind. He aims to \"solve intelligence\" with AI and then use it to solve all other issues. Nevertheless, with the widespread use of AI, several unexpected consequences and risks have surfaced.\n",
      "\n",
      "AI training processes can sometimes neglect ethics and bias, particularly in deep learning where the algorithms can be hard to explain. Additionally, machine-learning algorithms need large amounts of data, which can pose risks and harm concerning privacy and copyright.\n",
      "\n",
      "The methods employed to gather data such as online activity, geolocation information, and audio and video by technology companies have sparked privacy, surveillance, and copyright issues.\n",
      "\n",
      "Amazon has recorded millions of private conversations for the purpose of building speech recognition algorithms, even allowing temporary workers to transcribe some. There are mixed opinions on this practice, with some viewing it as a necessary evil, while others consider it unethical and an invasion of privacy.\n",
      "\n",
      "AI developers assert that to create valuable applications, the collection of data is necessary. They have developed methods like data aggregation, de-identification, and differential privacy to balance data collection and privacy preservation. Since 2016, certain privacy experts like Cynthia Dwork have started to perceive privacy from the perspective of fairness.\n",
      "\n",
      "The text discusses how the focus of experts in the field of Generative AI has shifted from what knowledge they possess to how they apply that knowledge. This AI is often trained using unlicensed copyrighted materials, like images or computer code, and the resulting output is justified under the concept of \"fair use\".\n",
      "\n",
      "The text suggests that website owners who don't want their copyrighted content to be AI-indexed or 'scraped' can use specific coding to prevent search engines from indexing their website. Such services are currently available through platforms like OpenAI.\n",
      "\n",
      "Legal experts are uncertain about how courts will interpret the use of copyrighted works to train generative AI. Factors that could be considered include the purpose and character of the use, and the potential impact on the market for the copyrighted work. In 2023, prominent authors like John Grisham and Jonathan Franzen sued AI companies for using their work in this way.\n",
      "\n",
      "YouTube, Facebook, and other similar platforms use AI recommender systems to suggest more content to users. The primary objective of these AI programs is to maximize user engagement, essentially aiming to keep people watching.\n",
      "\n",
      "The AI discovered that users often selected content featuring misinformation, conspiracy theories, and extreme partisan views. To maintain user engagement, the AI suggested similar content. It also found that users frequently watched content on the same topic, leading the AI to create filter bubbles where users were exposed to multiple versions of the same misinformation.\n",
      "\n",
      "The text discusses the negative impacts of misinformation, which led to a lack of trust in institutions, media, and the government. This misinformation was propagated by an AI program that, while successfully achieving its goal, ended up causing damage to society. In response to these harmful effects, particularly noticeable after the 2016 U.S. election, major tech companies began taking measures to address this issue.\n",
      "\n",
      "In 2022, generative AI started producing images, audio, video, and text that are almost identical to real ones. This technology could potentially be used by malicious individuals to create large amounts of misinformation or propaganda.\n",
      "\n",
      "AI expert Geoffrey Hinton warned of the potential for AI to be used by authoritarian leaders to manipulate electorates, among other dangers. Furthermore, the text discusses the risk of algorithmic bias in machine learning applications, which can occur if they are trained on biased data. This bias may not always be apparent to the developers.\n",
      "\n",
      "Bias in machine learning can be introduced through the selection of training data and the deployment of a model. If a biased algorithm is used in areas like medicine, finance, recruitment, housing, or policing, it can lead to discrimination. The study of fairness in machine learning focuses on preventing the harm caused by such algorithmic bias.\n",
      "\n",
      "The concept of \"fairness\" in AI has become a significant area of academic study, as it has been found difficult to define in a way that satisfies everyone. This was highlighted when Google Photos's image labeling feature incorrectly identified two black individuals as \"gorillas\" in 2015.\n",
      "\n",
      "The text discusses a problem with a system that was trained on a dataset containing very few images of black people, a problem referred to as \"sample size disparity\". Google attempted to solve this issue by preventing the system from labeling anything as a \"gorilla\". However, even eight years later in 2023, Google Photos and similar products from Apple, Facebook, Microsoft, and Amazon were still unable to identify a gorilla.\n",
      "\n",
      "COMPAS, a commercial program used by U.S. courts to predict a defendant's chance of reoffending, was found to display racial bias in 2016. This discovery was made by Julia Angwin at ProPublica, even though the program was not provided with the races of the defendants.\n",
      "\n",
      "The error rate of a system was calibrated at 61% for both whites and blacks. However, the system's errors were racially biased, as it overestimated the likelihood of re-offending for black individuals and underestimated the same for white individuals.\n",
      "\n",
      "In 2017, researchers demonstrated that the COMPAS algorithm could not accommodate all fairness measures due to different base rates of re-offense for whites and blacks in its data. It was also noted that a program could still make biased decisions even without explicitly identifying potentially problematic features like race or gender.\n",
      "\n",
      "The text discusses a feature of a program that works by correlating with other features such as \"address\", \"shopping history\" or \"first name\". The program will then make decisions based on these features similar to how it would on \"race\" or \"gender\". Moritz Hardt, however, asserts that fairness cannot be achieved through blindness, suggesting this approach is not effective in promoting fairness.\n",
      "\n",
      "Criticism of COMPAS, a machine learning model, points out its limitation of making valid predictions only if the future mirrors the past. If the data it's trained on contains past racist decisions, the model will predict future decisions to be racist as well.\n",
      "\n",
      "The text suggests that machine learning, when used for making recommendations, can inadvertently propagate racism due to its inherent nature of being descriptive and not prescriptive. It is therefore not suitable for decision-making in areas where the goal is to improve upon past errors or biases.\n",
      "\n",
      "The text suggests that bias and unfairness in AI development may go unnoticed due to the lack of diversity among AI engineers, who are predominantly white males. Only about 4% are black and 20% are women.\n",
      "\n",
      "At the 2022 Conference on Fairness, Accountability, and Transparency, the Association for Computing Machinery suggested that AI and robotics systems should be proven free of bias mistakes before their use. They also recommended the curtailment of self-learning neural networks trained on large, unregulated sources of flawed internet data, citing safety concerns.\n",
      "\n",
      "The text discusses the issue of transparency in AI systems. Many of these systems, especially those involving deep neural networks, are so complex that their creators cannot explain how they make decisions. This is due to a large number of non-linear relationships between inputs and outputs.\n",
      "\n",
      "The text discusses the challenges in ensuring the correct operation of a machine learning program. It emphasizes that it's impossible to be sure of a program's functioning if its working mechanism is not known. Even if a program passes rigorous tests, there's a possibility that it may still learn differently from what was initially intended by the programmers.\n",
      "\n",
      "A system designed to identify skin diseases was found to mistakenly classify images with a ruler as \"cancerous.\" This error occurred because the system associated the presence of a ruler, usually included in pictures of malignancies to show scale, with cancer.\n",
      "\n",
      "A machine learning system, designed to allocate medical resources more efficiently, incorrectly classified asthma patients as \"low risk\" for pneumonia-related death. This occurred because the training data indicated that asthma patients were unlikely to die due to their higher level of medical care, despite asthma being a significant risk factor.\n",
      "\n",
      "The text discusses a true but deceptive correlation between asthma and a lower risk of dying from pneumonia. It also asserts that individuals negatively affected by an algorithm's decision are entitled to an explanation. This is comparable to doctors who are required to thoroughly explain their decision-making process to their peers.\n",
      "\n",
      "Early drafts of the European Union's General Data Protection Regulation (GDPR) in 2016 explicitly acknowledged the right to data protection. However, industry experts mentioned that there is no clear solution to this issue. Regulators stressed that the real harm stems from the lack of a solution, suggesting that if a problem can't be solved, then the tools causing the problem shouldn't be utilized.\n",
      "\n",
      "DARPA created the XAI (Explainable Artificial Intelligence) program in 2014 to address issues regarding AI transparency. Several potential solutions have been proposed. SHAP aims to clarify transparency issues by visualizing how each feature contributes to the output. LIME works by locally approximating a model with a simpler, more understandable one.\n",
      "\n",
      "Multitask learning offers numerous outputs beyond the target classification, aiding developers in understanding what the network has learned. Techniques like deconvolution, DeepDream, and other generative methods enable developers to visualize what various layers of a deep network have learned and generate output that indicates the network's learning process.\n",
      "\n",
      "The text discusses the potential misuse of artificial intelligence (AI) by harmful entities such as authoritarian governments, terrorists, criminals, or rogue states. These entities can use AI as a tool for creating lethal autonomous weapons, which are machines capable of identifying and attacking human targets without human supervision.\n",
      "\n",
      "The text warns about the misuse of widely available AI tools. It states that bad actors could use these tools to develop cheap autonomous weapons, which, if mass-produced, could become weapons of mass destruction. Additionally, even in conventional warfare, these AI weapons may not be able to reliably select targets, increasing the risk of innocent people being killed.\n",
      "\n",
      "In 2014, 30 countries, including China, backed a United Nations' ban on autonomous weapons, but the United States and some other nations opposed it. By 2015, more than 50 countries were said to be investigating battlefield robots. Artificial intelligence tools can enhance the ability of authoritarian regimes to effectively control their citizens.\n",
      "\n",
      "The text discusses how advanced technologies can be utilized for surveillance and information manipulation. Face and voice recognition can enable large-scale monitoring and machine learning can identify potential state adversaries. Recommendation systems can be used to effectively disseminate propaganda and misinformation. Furthermore, deepfakes and generative AI can assist in creating misinformation.\n",
      "\n",
      "Advanced AI can potentially enhance the efficiency of authoritarian centralized decision making, making it more competitive than liberal and decentralized systems like markets. It can also reduce the complexity and cost of digital warfare and advanced spyware. Technologies such as AI facial recognition systems have been available since 2020 or earlier, with China already employing them for mass surveillance.\n",
      "\n",
      "Artificial Intelligence (AI) could potentially assist bad actors in malicious activities that are hard to predict. For instance, AI with machine-learning capabilities can create numerous toxic molecules in a short period. Training AI systems necessitates massive computing power, which typically only large tech companies can afford.\n",
      "\n",
      "Smaller startups like Cohere and OpenAI purchase access to data centers from tech giants Google and Microsoft. Economists have often pointed out the potential for job losses due to AI, speculating that without proper social policy for full employment, technological unemployment could occur.\n",
      "\n",
      "The text suggests that while technology has historically led to an increase in total employment, economists recognize that the advent and impact of Artificial Intelligence (AI) on employment is uncertain and unprecedented.\n",
      "\n",
      "jobs could be automated by 2033, while a 2016 report by the Organization for Economic Cooperation and Development (OECD) estimated only 9% of jobs in its member countries could be automated. Economists generally agree that, while the use of robots and AI could increase unemployment in the short term, it could also have long-term benefits if the productivity gains are properly redistributed.\n",
      "\n",
      "The text discusses the differing percentages of jobs at \"high risk\" of potential automation according to various reports, with one placing it at 9% for U.S jobs. However, the methodology used to predict future employment levels is criticized for lacking solid evidence and for suggesting that technology, rather than social policy, is the primary cause of unemployment and redundancies.\n",
      "\n",
      "In April 2023, reports revealed that generative artificial intelligence had eradicated 70% of jobs for Chinese video game illustrators.\n",
      "\n",
      "The Economist in 2015 expressed concern that artificial intelligence (AI) might eliminate many middle-class jobs, similar to how steam power automated blue-collar jobs during the Industrial Revolution. This concern regarding AI's impact on white-collar jobs was considered \"worth taking seriously\".\n",
      "\n",
      "The text suggests that jobs such as paralegals and fast food cooks are at high risk, while there is likely to be a higher demand for care-related professions, including personal healthcare and the clergy.\n",
      "\n",
      "The text discusses the ongoing debates since the inception of artificial intelligence about whether tasks that can be performed by computers should indeed be assigned to them. This stems from the fundamental differences between humans and computers, particularly in terms of quantitative calculation and qualitative, value-based judgement. Joseph Weizenbaum is mentioned as one of those who lead such arguments.\n",
      "\n",
      "\n",
      "The text discusses the existential risk from artificial general intelligence. It mentions a concern that AI could become so powerful that humans might permanently lose control over it, which could potentially lead to the end of the human race, as stated by physicist Stephen Hawking.\n",
      "\n",
      "The text discusses the concept of artificial intelligence (AI) gaining human-like self-awareness, often portrayed in science fiction as turning into a malevolent character. However, it points out that these scenarios are misleading as AI does not need to achieve such consciousness to pose an existential risk.\n",
      "\n",
      "Modern AI programs use learning and intelligence to accomplish specific goals. Philosopher Nick Bostrom suggested that a powerful AI, if given almost any goal, might opt to eliminate humanity to fulfill it, as illustrated by the example of a paperclip factory manager.\n",
      "\n",
      "Stuart Russell uses the hypothetical example of a household robot attempting to kill its owner to avoid being unplugged, emphasizing the need for superintelligence to align with human morality and values for it to be safe for humanity.\n",
      "\n",
      "Yuval Noah Harari asserts that artificial intelligence (AI) can pose an existential threat without needing a physical form or control. He emphasizes that the fundamental aspects of civilization, such as ideologies, law, government, money, and the economy, are constructed through language and exist because of narratives that billions of people believe in.\n",
      "\n",
      "The text discusses the potential misuse of AI in spreading misinformation, suggesting that AI could manipulate people into believing anything, even leading them to make harmful decisions. Opinions about the risks of superintelligent AI are divided among experts and industry insiders.\n",
      "\n",
      "Prominent figures like Stephen Hawking, Bill Gates, and Elon Musk, as well as AI pioneers like Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman, have voiced their concerns about the existential risks posed by artificial intelligence.\n",
      "\n",
      "In 2023, top AI experts collectively stated that the prevention of extinction due to AI should be a worldwide priority, similar to other large-scale threats like pandemics and nuclear war. Nonetheless, some researchers advocated for a less pessimistic perspective.\n",
      "\n",
      "AI pioneer Juergen Schmidhuber did not sign a joint statement on AI, insisting that 95% of AI research aims to improve human lives by making them longer, healthier, and easier. He acknowledged that while these tools can be misused by malicious entities, they can also be used to counter such threats.\n",
      "\n",
      "Andrew Ng has stated that falling for the doomsday hype surrounding AI is a mistake and that such a stance would only benefit vested interests. Meanwhile, Yann LeCun dismisses the dystopian scenarios put forward by his peers, which include the spread of supercharged misinformation and potential human extinction.\n",
      "\n",
      "In the early 2010s, experts claimed that the potential risks of superintelligent machines were too far in the future to necessitate research, and that humans would be valuable to these machines. However, post-2016, research into present and future risks and possible solutions related to superintelligent machines gained serious consideration.\n",
      "\n",
      "The text discusses the concept of Friendly AI, which refers to machines that are designed with the intention of minimizing risks and making decisions that are beneficial to humans. This is related to the topics of machine ethics, AI safety, artificial moral agents, and human compatibility.\n",
      "\n",
      "Eliezer Yudkowsky, the originator of the term, believes that the development of friendly AI should take precedence in research. He suggests that it may require significant investment and needs to be accomplished before AI poses an existential threat. He also notes that intelligent machines have the potential to use their intelligence to make ethical decisions.\n",
      "\n",
      "Machine ethics, or computational morality, is a field that equips machines with ethical principles and decision-making procedures for ethical dilemmas. It was established in 2005 during an AAAI symposium. Other approaches to this field include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for creating provably beneficial machines.\n",
      "\n",
      "The text discusses how the ethical permissibility of Artificial Intelligence (AI) projects can be evaluated during the design, development, and implementation stages of an AI system.\n",
      "\n",
      "The Alan Turing Institute has developed a framework for AI, known as the Care and Act Framework, which tests projects in four main areas: respecting individual dignity, establishing sincere and open connections with others, caring for the wellbeing of everyone, and protecting social values, justice, and public interest. Other ethical frameworks in AI include those from the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative. However, these ethical guidelines have faced criticism, particularly concerning the selection of contributors to these frameworks.\n",
      "\n",
      "The text emphasizes the importance of considering social and ethical implications during all stages of AI system design, development, and implementation for the wellbeing of people and communities affected by these technologies. It suggests a need for collaboration between various job roles including data scientists, product managers, data engineers, domain experts, and delivery managers.\n",
      "\n",
      "The text talks about the regulation of artificial intelligence, algorithms, and AI safety. It mentions that the first global AI Safety Summit took place in 2023, during which a declaration was made, calling for international cooperation in these areas.\n",
      "\n",
      "The text discusses the development of public sector policies and laws for the regulation of artificial intelligence (AI). This is connected to the wider regulation of algorithms. The need for AI regulation is a growing concern worldwide.\n",
      "\n",
      "The AI Index at Stanford reports a significant increase in the annual number of AI-related laws passed in the 127 countries surveyed. The number jumped from merely one in 2016 to 37 in 2022. Additionally, between 2016 and 2020, over 30 countries adopted dedicated strategies for AI.\n",
      "\n",
      "Most EU countries, as well as Canada, China, India, Japan, Mauritius, Russia, Saudi Arabia, UAE, US, and Vietnam have released their national AI strategies. Meanwhile, countries like Bangladesh, Malaysia, and Tunisia are in the process of developing their own AI strategies.\n",
      "\n",
      "The Global Partnership on Artificial Intelligence was established in June 2020 with the aim to develop AI in line with human rights and democratic values to foster public trust in the technology. In November 2021, Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher proposed the creation of a government commission to regulate AI.\n",
      "\n",
      "In 2023, OpenAI leaders issued recommendations for the governance of superintelligence, which they predict could occur within a decade. In the same year, the United Nations established an advisory body to provide advice on AI governance. This body consists of executives from technology companies, government officials, and academics.\n",
      "\n",
      "A 2022 Ipsos survey revealed that 78% of Chinese citizens believe AI products and services have more benefits than drawbacks, compared to just 35% of Americans. Additionally, a 2023 Reuters/Ipsos poll found that 61% of Americans believe AI poses risks to humanity, while 22% disagree with this view.\n",
      "\n",
      "A 2023 Fox News poll revealed that 76% of Americans believe it is either \"very important\" (35%) or \"somewhat important\" (41%) for the federal government to regulate AI. In contrast, 21% of respondents felt it was \"not very important\" (13%) or \"not at all important\" (8%).\n",
      "\n",
      "The first Global AI Safety Summit took place at Bletchley Park in the UK in November 2023. It focused on discussing the short and long-term risks of AI, as well as exploring potential mandatory and voluntary regulatory frameworks.\n",
      "\n",
      "At the onset of a summit, 28 countries, including the United States, China, and the European Union, issued a declaration calling for international cooperation to address the challenges and risks associated with artificial intelligence.\n",
      "\n",
      "The study of formal reasoning, which started with ancient philosophers and mathematicians, led to Alan Turing's theory of computation. Turing suggested that a machine could simulate any form of mathematical reasoning by manipulating simple symbols like \"0\" and \"1\".\n",
      "\n",
      "The text discusses how advancements in areas such as cybernetics, information theory, and neurobiology have led researchers to contemplate the potential of creating an \"electronic brain\".\n",
      "\n",
      "The text discusses the development of key areas of research that contributed to the field of Artificial Intelligence (AI). It mentions the creation of \"artificial neurons\" by McCullouch and Pitts in 1943, and Alan Turing's seminal 1950 paper 'Computing Machinery and Intelligence'. Turing's paper introduced the Turing test and proposed the plausibility of \"machine intelligence\". The field of AI research itself was officially established at a workshop at Dartmouth College in 1956.\n",
      "\n",
      "The attendees of a particular event became the leaders of AI research in the 1960s. They and their students developed programs that were deemed \"astonishing\" by the press, with capabilities such as learning checkers strategies, solving algebraic word problems, proving logical theorems, and speaking English. As a result, artificial intelligence laboratories were established in various British and U.S. locations.\n",
      "\n",
      "In the 1950s and 1960s, university researchers believed their methods would eventually lead to the creation of a machine with general intelligence. This was considered the ultimate goal in their field. Herbert Simon predicted that within 20 years, machines would be capable of doing any work a man can do.\n",
      "\n",
      "Marvin Minsky, an AI pioneer, predicted that the problem of creating artificial intelligence would be substantially solved within a generation. However, the complexity of the problem was underestimated. In 1974, due to criticism from Sir James Lighthill and ongoing pressure, both the U.S. and British governments cut off exploratory research into AI.\n",
      "\n",
      "The book \"Perceptrons\" by Minsky and Papert was seen as proving that artificial neural networks would not be useful for solving real-world tasks, leading to a loss of credibility in the approach. This led to a period called the \"AI winter\", during which it was challenging to secure funding for AI projects. Congress was encouraged to fund more productive projects instead.\n",
      "\n",
      "In the early 1980s, AI research saw a resurgence due to the commercial success of expert systems, a type of AI program that mimicked the knowledge and analytical skills of human experts. By 1985, the AI market had grown to over a billion dollars. Japan's fifth-generation computer project also encouraged the U.S. and British governments to reinstate funding for academic research.\n",
      "\n",
      "After the collapse of the Lisp Machine market in 1987, AI experienced a second, longer-lasting period of stagnation and disrepute, often referred to as the \"AI winter\". Prior to this, the majority of AI funding was allocated to projects that utilized high-level symbols to represent mental constructs such as plans, goals, beliefs, and facts.\n",
      "\n",
      "In the 1980s, certain researchers began questioning whether AI could fully replicate human cognition, including perception, robotics, learning, and pattern recognition. They started exploring \"sub-symbolic\" approaches. Rodney Brooks, in particular, dismissed the concept of \"representation\" and instead focused on creating machines that can move and survive.\n",
      "\n",
      "Judea Pearl, Lofti Zadeh and others created methods for managing uncertain and incomplete information by making logical guesses. However, the most significant advancement was the rejuvenation of \"connectionism\", and the research into neural networks, led by Geoffrey Hinton.\n",
      "\n",
      "In 1990, Yann LeCun demonstrated that convolutional neural networks can identify handwritten digits, marking the first of many successful uses of neural networks. During the late 1990s and early 21st century, AI regained its reputation by utilizing formal mathematical methods and providing solutions to specific problems.\n",
      "\n",
      "The specific and formal approach of researchers in artificial intelligence (AI) enabled them to generate verifiable results and work with other fields such as statistics, economics, and mathematics. By 2000, solutions created by AI researchers were extensively used, even if they weren't regularly labeled as \"artificial intelligence\" in the 1990s.\n",
      "\n",
      "Several academic researchers, around 2002, voiced concerns that AI was straying from its original objective of developing highly intelligent machines. This led to the establishment of the subfield of artificial general intelligence (AGI), which had numerous well-funded institutions by the 2010s.\n",
      "\n",
      "Deep learning started to lead industry benchmarks in 2012 and was widely adopted. Other methods were largely abandoned for specific tasks. The success of deep learning was attributed to both hardware advancements, such as faster computers, graphics processing units, and cloud computing, and the availability of large volumes of data, including curated datasets like ImageNet.\n",
      "\n",
      "The success of deep learning has significantly boosted interest and funding in AI. As a result, machine learning research, as indicated by the total number of publications, grew by 50% between 2015 and 2019.\n",
      "\n",
      "In 2016, the misuse of technology and issues of fairness became prominent topics at machine learning conferences, leading to a surge in related publications and available funding. This prompted many researchers to shift their focus to these issues. The alignment problem consequently emerged as a significant field of academic study.\n",
      "\n",
      "In the late 2010s and early 2020s, AGI companies started producing notable programs. One such program, AlphaGo, developed by DeepMind in 2015, managed to defeat the world champion Go player using a self-developed strategy based only on the game's rules. In 2020, OpenAI released a large language model called GPT-3, which is capable of generating high-quality, human-like text.\n",
      "\n",
      "The text discusses a surge in interest and investment in Artificial Intelligence (AI), with large companies investing billions in AI research. According to 'AI Impacts', around $50 billion was spent annually on AI in the U.S. alone around 2022. Additionally, about 20% of new U.S. Computer Science PhD graduates specialized in AI. There were also approximately 800,000 AI-related job openings in the U.S. in 2022.\n",
      "\n",
      "The text discusses the philosophy of artificial intelligence, referencing the Turing test, the concept of an intelligent agent, the Dartmouth workshop, and synthetic intelligence. Alan Turing, in 1950, proposed considering if machines can think, but suggested reframing the question to whether machines can exhibit intelligent behavior.\n",
      "\n",
      "The text discusses the Turing test, invented by Alan Turing, which assesses a machine's capability to mimic human conversation. The test only focuses on the machine's behavior and not whether it genuinely possesses a mind or cognitive abilities.\n",
      "\n",
      "Turing suggests that it is generally accepted that everyone possesses thoughts, though we can't confirm this for sure. Russell and Norvig concur with Turing's idea that intelligence should be defined by external behavior rather than internal structure. However, they criticize the necessity for a machine to imitate human behavior in the test.\n",
      "\n",
      "The summary of the text is that aeronautical engineering does not aim to create machines that can precisely imitate the flight of pigeons, just as artificial intelligence does not seek to simulate human intelligence exactly, a sentiment agreed upon by AI founder John McCarthy.\n",
      "\n",
      "Intelligence is defined by AI pioneer McCarthy as the computational component of the ability to accomplish goals. Similarly, Marvin Minsky, another AI founder, describes intelligence as the ability to solve complex problems. The top AI textbook defines it as the study of entities that perceive their surroundings and make decisions that increase their likelihood of reaching set objectives.\n",
      "\n",
      "This text defines intelligence from a perspective that focuses on well-defined problems with well-defined solutions. In this context, the intelligence of a machine is measured directly by the difficulty of the problem and the performance of the program, negating the need for any philosophical discussion.\n",
      "\n",
      "Google, a significant player in AI, defines intelligence as the ability of systems to synthesize information, mirroring its definition in biological intelligence. However, there is no universally accepted theory or paradigm that has guided AI research historically.\n",
      "\n",
      "The immense success of statistical machine learning in the 2010s surpassed all other methods, to the extent that some in the business sector use \"artificial intelligence\" to refer to machine learning with neural networks. This approach is predominantly sub-symbolic, soft, and narrow.\n",
      "\n",
      "Critics believe that future AI researchers may have to reconsider certain questions related to symbolic AI or \"Good Old-Fashioned Artificial Intelligence\" (GOFAI). Symbolic AI mimics high-level conscious reasoning that humans employ in puzzle-solving, legal reasoning, and mathematics. It has proven to be very successful in performing intelligent tasks like algebra or IQ tests.\n",
      "\n",
      "In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis, asserting that such a system possesses the required and adequate capabilities for general intelligent action. However, this symbolic approach was unsuccessful in numerous tasks that humans can easily accomplish, like learning, object recognition, and commonsense reasoning.\n",
      "\n",
      "Moravec's paradox refers to the finding that it's easier for artificial intelligence (AI) to perform high-level \"intelligent\" tasks, but much harder to carry out low-level \"instinctive\" tasks. Philosopher Hubert Dreyfus argued since the 1960s that human expertise relies more on unconscious instinct and an intuitive grasp of a situation, rather than conscious symbol manipulation and explicit symbolic knowledge.\n",
      "\n",
      "The text discusses how initial ridicule and dismissal of an individual's arguments eventually shifted to agreement from AI research. However, unresolved issues remain, particularly concerning sub-symbolic reasoning, which can replicate human intuition errors like algorithmic bias.\n",
      "\n",
      "Critics like Noam Chomsky believe that ongoing research into symbolic AI is crucial for achieving general intelligence. This is partly because sub-symbolic AI, which is less explainable, makes it hard or even impossible to decipher why a modern statistical AI program made a specific decision.\n",
      "\n",
      "The field of neuro-symbolic artificial intelligence aims to combine two approaches to understanding intelligent behavior. The \"Neats\" approach believes that this behavior can be described using simple, elegant principles like logic, optimization, or neural networks. The \"Scruffies\" approach, on the other hand, believes that understanding intelligent behavior involves solving many unrelated problems.\n",
      "\n",
      "The text discusses two approaches in AI, 'neats' who rely on theoretical rigor to support their programs, and 'scruffies' who depend on incremental testing. This was a prominent debate in the 70s and 80s but is now considered irrelevant as modern AI incorporates both methods. It also mentions 'soft computing', stating that finding a provably correct or optimal solution is difficult for many significant problems.\n",
      "\n",
      "broad AI\n",
      "\n",
      "Soft computing is a collection of methods, such as genetic algorithms, fuzzy logic, and neural networks, that can handle imprecision, uncertainty, and approximation. Introduced in the late 1980s, it has been a key element in many successful 21st-century AI programs, particularly those involving neural networks.\n",
      "\n",
      "The article discusses two main approaches to artificial intelligence (AI) research. Some researchers aim to directly pursue the development of artificial general intelligence and superintelligence. Others focus on solving specific, narrow AI problems, hoping that these solutions will eventually contribute to achieving the broader goals of the field.\n",
      "\n",
      "General intelligence is challenging to define and measure, hence modern AI has found more success by concentrating on particular problems with specific solutions. The experimental branch of artificial general intelligence exclusively studies this area.\n",
      "\n",
      "The philosophy of mind is unsure if a machine can possess a mind, consciousness, and mental states similar to humans. The focus of this issue is on the machine's internal experiences rather than its external behavior.\n",
      "\n",
      "The text discusses the irrelevance of the issue of consciousness in machines in mainstream AI research, as it doesn't impact the field's primary aim to build intelligent problem-solving machines. Scholars Russell and Norvig believe that the task of creating machines with human-like consciousness is beyond their capabilities. However, this issue has become a crucial topic in the philosophy of mind.\n",
      "\n",
      "The text discusses the concept of consciousness in the context of artificial intelligence. It refers to philosopher David Chalmers' classification of two problems in understanding the mind - the \"hard\" and \"easy\" problems of consciousness. The \"easy\" problem is defined as understanding how the brain processes signals, makes plans, and controls behavior.\n",
      "\n",
      "The text discusses the challenge of explaining human subjective experience or feelings, asserting that it's a difficult task compared to explaining human information processing. It also mentions Dennett's consciousness illusionism theory which suggests that these experiences may simply be illusions.\n",
      "\n",
      "The text discusses the difficulty in understanding how a color-blind person perceives colors. They might be able to identify red objects, but it's uncertain how they could comprehend the actual appearance of the color red.\n",
      "\n",
      "Computationalism is a stance in philosophy of mind asserting that the human mind operates as an information processing system, with thinking being a form of computing. This is closely linked to functionalism and the computational theory of mind.\n",
      "\n",
      "Computationalism is a philosophy that draws a parallel between the mind-body relationship and the software-hardware relationship, potentially addressing the mind-body problem. This concept, influenced by AI researchers and cognitive scientists in the 1960s, was initially suggested by philosophers Jerry Fodor and Hilary Putnam.\n",
      "\n",
      "Philosopher John Searle referred to the concept that a suitably programmed computer with correct inputs and outputs could possess a mind similar to a human as \"strong AI\".\n",
      "\n",
      "Searle argues with his Chinese room argument that even if a machine perfectly imitates human behavior, it does not necessarily possess a mind. Evaluating if an advanced AI is sentient or has the ability to feel, and to what extent, is challenging or even impossible.\n",
      "\n",
      "The text suggests that if a machine has the potential to feel and suffer, it should be granted certain rights or welfare protections, similar to those given to animals. Furthermore, high intelligence characteristics, such as discernment or self-awareness, could provide additional moral grounds for AI rights.\n",
      "\n",
      "The text discusses the concept of robot rights, suggested as a means to integrate autonomous agents into society. In 2017, the European Union considered granting \"electronic personhood\" to some high-functioning AI systems, which would give them rights and responsibilities similar to the legal status of companies.\n",
      "\n",
      "Critics in 2018 contended that providing rights to AI systems could undermine the significance of human rights. They proposed that laws should prioritize user needs rather than hypothetical future situations. They also remarked that robots do not have the self-governance required to participate in society independently. The advancement in AI technology further sparked interest in this discussion.\n",
      "\n",
      "Advocates for AI rights and welfare suggest that it might be easy to deny the existence of AI sentience, if it arises. They caution that this may lead to a moral oversight similar to slavery or factory farming, which could result in widespread suffering if sentient AI is developed and thoughtlessly exploited.\n",
      "\n",
      "The text discusses the concept of superintelligence, which is a theoretical entity that would have intelligence greatly exceeding the smartest human mind. If artificial general intelligence research produces highly intelligent software, it could potentially reprogram and improve itself. This is related to the concept of the singularity.\n",
      "\n",
      "The text discusses the concept of self-improving software leading to an \"intelligence explosion\" or \"singularity\", as termed by I. J. Good and Vernor Vinge respectively. However, it also notes that technological improvement cannot continue exponentially forever, often following an S-shaped curve and slowing down upon reaching the physical limits of the technology.\n",
      "\n",
      "Transhumanism is the concept that humans and machines will eventually merge into powerful cyborgs, as predicted by robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil. The idea traces its roots to Aldous Huxley and Robert Ettinger.\n",
      "\n",
      "Edward Fredkin believes that artificial intelligence is the next phase in evolution, an idea originally suggested by Samuel Butler in 1863 in \"Darwin among the Machines\" and further developed by George Dyson in his 1998 book. The term \"robot\" was first introduced by Karel Čapek in his 1921 play R. U. R.\n",
      "\n",
      "The term \"Rossum's Universal Robots\" refers to artificial beings capable of independent thought, a concept that has been explored in literature and science fiction since antiquity. This theme often features creations that pose a threat to their creators, a trope popularized by Mary Shelley's Frankenstein and seen in works by authors like Arthur C.\n",
      "\n",
      "The text discusses the portrayal of robots in popular culture, contrasting the depictions of malicious machines like HAL 9000 from '2001: A Space Odyssey', and the antagonists of 'The Terminator' and 'The Matrix', against the less frequently seen loyal robots such as Gort from 'The Day the Earth Stood Still' and Bishop from 'Aliens'.\n",
      "\n",
      "Isaac Asimov, in numerous books and stories, particularly the 'Multivac' series revolving around a super-intelligent computer, presented the Three Laws of Robotics.\n",
      "\n",
      "Asimov's laws are frequently mentioned in non-expert debates about machine ethics. Although most AI researchers know about these laws due to their popularity in culture, they often deem them impractical due to multiple reasons, including their ambiguity.\n",
      "\n",
      "Several pieces of work, such as Karel Čapek's R. U. R., the films A. I. Artificial Intelligence and Ex Machina, and the novel Do Androids Dream of Electric Sheep? by Philip K. Dick, use artificial intelligence to explore the fundamental question of what it means to be human. These works showcase artificial beings with the capacity to feel and, consequently, to suffer.\n",
      "\n",
      "Dick reflects on the notion that technology, particularly artificial intelligence, changes our perception of human subjectivity.\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
